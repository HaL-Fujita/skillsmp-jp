#!/usr/bin/env python3
"""
GitHub APIã‚’ä½¿ã£ã¦Claudeã‚¹ã‚­ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ã„æ–¹:
    python scripts/fetch_skills.py

å¿…è¦ãªç’°å¢ƒå¤‰æ•°:
    GITHUB_TOKEN: GitHub Personal Access Tokenï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ç·©å’Œï¼‰
    OPENAI_API_KEY: OpenAI APIã‚­ãƒ¼ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€é«˜å“è³ªç¿»è¨³ç”¨ï¼‰
    TRANSLATION_METHOD: ç¿»è¨³æ–¹æ³• (googletrans/openai/none) ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: googletrans
"""

import json
import os
import sys
import time
from datetime import datetime
from typing import List, Dict, Any, Optional
import urllib.request
import urllib.error

# GitHub APIè¨­å®š
GITHUB_API_BASE = "https://api.github.com"
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN", "")

# ç¿»è¨³è¨­å®š
TRANSLATION_METHOD = os.getenv("TRANSLATION_METHOD", "googletrans")  # googletrans, openai, none
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

# ã‚«ãƒ†ã‚´ãƒªãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆè‹±èªâ†’æ—¥æœ¬èªï¼‰
CATEGORY_MAP = {
    "Developer Tools": "é–‹ç™ºè€…ãƒ„ãƒ¼ãƒ«",
    "Web & App Development": "Web & ã‚¢ãƒ—ãƒªé–‹ç™º",
    "Data Science": "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹",
    "Database": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹",
    "DevOps": "DevOps",
    "Documentation": "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ",
    "Testing": "ãƒ†ã‚¹ãƒˆ",
    "Security": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£",
    "Utilities": "ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£",
    "Agents & Automation": "ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ & è‡ªå‹•åŒ–",
    "Documents & Content": "ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ & ã‚³ãƒ³ãƒ†ãƒ³ãƒ„",
    "API & Backend": "API & ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰",
    "DevOps & Infrastructure": "DevOps & ã‚¤ãƒ³ãƒ•ãƒ©",
    "Testing & QA": "ãƒ†ã‚¹ãƒˆ & QA",
    "Skills & Workflow": "ã‚¹ã‚­ãƒ« & ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼",
}


def github_api_request(url: str, allow_404: bool = False) -> Dict[str, Any]:
    """GitHub APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡"""
    headers = {
        "Accept": "application/vnd.github.v3+json",
        "User-Agent": "skillsmp-jp-fetcher",
    }
    if GITHUB_TOKEN:
        headers["Authorization"] = f"token {GITHUB_TOKEN}"

    req = urllib.request.Request(url, headers=headers)

    try:
        with urllib.request.urlopen(req) as response:
            return json.loads(response.read().decode())
    except urllib.error.HTTPError as e:
        if e.code == 404 and allow_404:
            return {}
        print(f"Error: {e.code} - {e.reason}")
        print(f"URL: {url}")
        if e.code == 403:
            print("Rate limit exceeded. Set GITHUB_TOKEN environment variable.")
        if not allow_404:
            sys.exit(1)
        return {}


def get_anthropics_skills_repo() -> Dict[str, Any]:
    """anthropics/skillsãƒªãƒã‚¸ãƒˆãƒªã®æƒ…å ±ã‚’å–å¾—"""
    print("Fetching anthropics/skills repository...")
    url = f"{GITHUB_API_BASE}/repos/anthropics/skills"
    return github_api_request(url)


def get_repo_contents(repo_full_name: str, path: str = "") -> List[Dict[str, Any]]:
    """ãƒªãƒã‚¸ãƒˆãƒªã®ç‰¹å®šãƒ‘ã‚¹ã®å†…å®¹ã‚’å–å¾—"""
    url = f"{GITHUB_API_BASE}/repos/{repo_full_name}/contents/{path}"
    return github_api_request(url)


def get_last_commit_date(repo_full_name: str, path: str) -> Optional[str]:
    """ç‰¹å®šãƒ‘ã‚¹ã®æœ€çµ‚ã‚³ãƒŸãƒƒãƒˆæ—¥ã‚’å–å¾—"""
    try:
        url = f"{GITHUB_API_BASE}/repos/{repo_full_name}/commits?path={path}&per_page=1"
        commits = github_api_request(url, allow_404=True)

        if commits and len(commits) > 0:
            commit_date = commits[0]['commit']['committer']['date']
            # ISO 8601å½¢å¼ (2024-01-15T10:30:00Z) ã‚’ YYYY-MM-DDå½¢å¼ã«å¤‰æ›
            return commit_date.split('T')[0]
        return None
    except Exception as e:
        print(f"  Warning: Could not fetch commit date: {e}")
        return None


def get_repo_statistics(repo_full_name: str) -> Dict[str, Any]:
    """ãƒªãƒã‚¸ãƒˆãƒªã®è©³ç´°çµ±è¨ˆæƒ…å ±ã‚’å–å¾—"""
    print(f"  Fetching repository statistics...")

    # åŸºæœ¬çš„ãªãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±
    repo_url = f"{GITHUB_API_BASE}/repos/{repo_full_name}"
    repo_data = github_api_request(repo_url, allow_404=True)

    if not repo_data:
        return {}

    # ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼æ•°ã‚’å–å¾—
    contributors_url = f"{GITHUB_API_BASE}/repos/{repo_full_name}/contributors?per_page=1"
    try:
        req = urllib.request.Request(contributors_url)
        if GITHUB_TOKEN:
            req.add_header("Authorization", f"token {GITHUB_TOKEN}")
        req.add_header("User-Agent", "skillsmp-jp-fetcher")

        with urllib.request.urlopen(req) as response:
            # Linkãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰ç·ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚¿ãƒ¼æ•°ã‚’å–å¾—
            link_header = response.headers.get('Link', '')
            contributors_count = 1
            if 'rel="last"' in link_header:
                import re
                match = re.search(r'page=(\d+)>; rel="last"', link_header)
                if match:
                    contributors_count = int(match.group(1))
    except Exception as e:
        print(f"  Warning: Could not fetch contributors count: {e}")
        contributors_count = None

    # ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆæ•°ã‚’å–å¾—ï¼ˆã‚ªãƒ¼ãƒ—ãƒ³ï¼‰
    pulls_url = f"{GITHUB_API_BASE}/repos/{repo_full_name}/pulls?state=open&per_page=1"
    try:
        req = urllib.request.Request(pulls_url)
        if GITHUB_TOKEN:
            req.add_header("Authorization", f"token {GITHUB_TOKEN}")
        req.add_header("User-Agent", "skillsmp-jp-fetcher")

        with urllib.request.urlopen(req) as response:
            link_header = response.headers.get('Link', '')
            open_pulls_count = 0
            if 'rel="last"' in link_header:
                import re
                match = re.search(r'page=(\d+)>; rel="last"', link_header)
                if match:
                    open_pulls_count = int(match.group(1))
    except Exception as e:
        print(f"  Warning: Could not fetch pull requests count: {e}")
        open_pulls_count = None

    statistics = {
        "stars": repo_data.get("stargazers_count", 0),
        "forks": repo_data.get("forks_count", 0),
        "watchers": repo_data.get("watchers_count", 0),
        "openIssues": repo_data.get("open_issues_count", 0),
        "openPullRequests": open_pulls_count,
        "contributors": contributors_count,
        "language": repo_data.get("language", "Unknown"),
        "license": repo_data.get("license", {}).get("name", None) if repo_data.get("license") else None,
        "size": repo_data.get("size", 0),  # KBå˜ä½
        "defaultBranch": repo_data.get("default_branch", "main"),
        "createdAt": repo_data.get("created_at", "").split('T')[0] if repo_data.get("created_at") else None,
        "pushedAt": repo_data.get("pushed_at", "").split('T')[0] if repo_data.get("pushed_at") else None,
    }

    print(f"    â­ Stars: {statistics['stars']:,} | ğŸ´ Forks: {statistics['forks']:,} | ğŸ‘¥ Contributors: {statistics['contributors'] or 'N/A'}")

    return statistics


def fetch_skill_md(repo_full_name: str, skill_path: str) -> Dict[str, Any]:
    """ã‚¹ã‚­ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰SKILL.mdã‚’å–å¾—ã—ã¦ãƒ‘ãƒ¼ã‚¹"""
    import base64
    import re

    try:
        # SKILL.mdã‚’å–å¾—
        url = f"{GITHUB_API_BASE}/repos/{repo_full_name}/contents/{skill_path}/SKILL.md"
        content_data = github_api_request(url, allow_404=True)

        if not content_data:
            return {}

        if content_data.get("encoding") == "base64":
            content = base64.b64decode(content_data["content"]).decode("utf-8")

            # YAMLãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ã‚’æŠ½å‡º
            match = re.match(r"^---\n(.*?)\n---", content, re.DOTALL)
            if match:
                yaml_content = match.group(1)
                data = {}
                for line in yaml_content.split("\n"):
                    if ":" in line:
                        key, value = line.split(":", 1)
                        data[key.strip()] = value.strip().strip('"\'')
                return data
    except Exception as e:
        print(f"  Warning: Could not fetch SKILL.md: {e}")

    return {}


def translate_with_googletrans(text: str) -> Optional[str]:
    """googletransãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ã£ã¦ç¿»è¨³"""
    try:
        from googletrans import Translator
        translator = Translator()
        result = translator.translate(text, src='en', dest='ja')
        time.sleep(0.5)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        return result.text
    except ImportError:
        print("  Warning: googletrans not installed. Run: pip install googletrans==4.0.0-rc1")
        return None
    except Exception as e:
        print(f"  Warning: Translation failed with googletrans: {e}")
        return None


def translate_with_openai(text: str) -> Optional[str]:
    """OpenAI APIã‚’ä½¿ã£ã¦ç¿»è¨³"""
    if not OPENAI_API_KEY:
        print("  Warning: OPENAI_API_KEY not set")
        return None

    try:
        import json

        url = "https://api.openai.com/v1/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {OPENAI_API_KEY}"
        }

        data = {
            "model": "gpt-3.5-turbo",
            "messages": [
                {"role": "system", "content": "ã‚ãªãŸã¯æŠ€è¡“æ–‡æ›¸ã®ç¿»è¨³ã‚’å°‚é–€ã¨ã™ã‚‹ç¿»è¨³è€…ã§ã™ã€‚è‹±èªã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è‡ªç„¶ãªæ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"},
                {"role": "user", "content": f"ä»¥ä¸‹ã®è‹±èªãƒ†ã‚­ã‚¹ãƒˆã‚’æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ï¼š\n\n{text}"}
            ],
            "temperature": 0.3
        }

        req = urllib.request.Request(
            url,
            data=json.dumps(data).encode('utf-8'),
            headers=headers
        )

        with urllib.request.urlopen(req) as response:
            result = json.loads(response.read().decode())
            translated = result['choices'][0]['message']['content'].strip()
            time.sleep(0.5)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            return translated

    except Exception as e:
        print(f"  Warning: Translation failed with OpenAI: {e}")
        return None


def translate_text(text: str, method: str = TRANSLATION_METHOD) -> str:
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šã•ã‚ŒãŸæ–¹æ³•ã§ç¿»è¨³"""
    if not text or method == "none":
        return text

    translated = None

    if method == "openai":
        translated = translate_with_openai(text)
    elif method == "googletrans":
        translated = translate_with_googletrans(text)

    # ç¿»è¨³å¤±æ•—æ™‚ã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™
    return translated if translated else text


def create_skill_data(repo: Dict[str, Any], skill_name: str, skill_data: Dict[str, Any], updated_at: Optional[str] = None, statistics: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """ã‚¹ã‚­ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
    # IDã‚’ç”Ÿæˆ
    skill_id = f"{repo['owner']['login']}-{skill_name}".lower().replace("_", "-")

    # ã‚«ãƒ†ã‚´ãƒªã‚’æ—¥æœ¬èªã«å¤‰æ›
    category_en = skill_data.get("category", "Developer Tools")
    category_ja = CATEGORY_MAP.get(category_en, "é–‹ç™ºè€…ãƒ„ãƒ¼ãƒ«")

    # ã‚¿ã‚°ã‚’ç”Ÿæˆ
    tags = []
    if skill_data.get("tags"):
        tags = [tag.strip() for tag in skill_data.get("tags", "").split(",")][:5]

    # è‹±èªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    name_en = skill_data.get("name", skill_name)
    description_en = skill_data.get("description", "")

    # æ—¥æœ¬èªã«ç¿»è¨³
    if TRANSLATION_METHOD != "none":
        print(f"    Translating '{name_en}'...")
        name_ja = translate_text(name_en)
        description_ja = translate_text(description_en)
    else:
        name_ja = name_en
        description_ja = description_en

    # ã‚¹ã‚­ãƒ«ãƒ‡ãƒ¼ã‚¿
    skill = {
        "id": skill_id,
        "name": name_ja,
        "nameEn": name_en,
        "description": description_ja,
        "descriptionEn": description_en,
        "category": category_ja,
        "categoryEn": category_en,
        "author": repo["owner"]["login"],
        "stars": statistics.get("stars", repo["stargazers_count"]) if statistics else repo["stargazers_count"],
        "downloads": None,
        "updatedAt": updated_at if updated_at else datetime.now().strftime("%Y-%m-%d"),
        "tags": tags if tags else ["skill"],
        "githubUrl": f"{repo['html_url']}/tree/main/{skill_name}",
        "installCommand": None,
        # GitHubçµ±è¨ˆæƒ…å ±
        "github": {
            "forks": statistics.get("forks", 0) if statistics else 0,
            "watchers": statistics.get("watchers", 0) if statistics else 0,
            "openIssues": statistics.get("openIssues", 0) if statistics else 0,
            "openPullRequests": statistics.get("openPullRequests", 0) if statistics else 0,
            "contributors": statistics.get("contributors") if statistics else None,
            "language": statistics.get("language", "Unknown") if statistics else "Unknown",
            "license": statistics.get("license") if statistics else None,
            "size": statistics.get("size", 0) if statistics else 0,
            "createdAt": statistics.get("createdAt") if statistics else None,
            "pushedAt": statistics.get("pushedAt") if statistics else None,
        } if statistics else None,
    }

    return skill


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("Claude Skills Data Fetcher with Auto-Translation")
    print("=" * 50)
    print(f"Translation Method: {TRANSLATION_METHOD}")
    if TRANSLATION_METHOD == "openai":
        print(f"OpenAI API Key: {'Set' if OPENAI_API_KEY else 'Not Set'}")
    print()

    # anthropics/skillsãƒªãƒã‚¸ãƒˆãƒªã‚’å–å¾—
    repo = get_anthropics_skills_repo()
    print(f"Repository: {repo['full_name']}")
    print(f"Stars: {repo['stargazers_count']}")
    print()

    # ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
    print("Fetching skills list...")
    contents = get_repo_contents(repo["full_name"], "")

    # ã‚¹ã‚­ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ã™
    skill_dirs = []
    for item in contents:
        if item["type"] == "dir" and not item["name"].startswith("."):
            skill_dirs.append(item["name"])

    print(f"Found {len(skill_dirs)} potential skill directories")
    print()

    # ãƒªãƒã‚¸ãƒˆãƒªå…¨ä½“ã®çµ±è¨ˆæƒ…å ±ã‚’1å›å–å¾—
    print("Fetching repository statistics (this may take a moment)...")
    repo_statistics = get_repo_statistics(repo["full_name"])
    print()

    # å„ã‚¹ã‚­ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    skills = []
    for i, skill_name in enumerate(skill_dirs[:50], 1):  # æœ€å¤§50å€‹
        print(f"Processing [{i}/{min(len(skill_dirs), 50)}]: {skill_name}")

        # SKILL.mdã‚’å–å¾—
        skill_data = fetch_skill_md(repo["full_name"], skill_name)

        if skill_data and skill_data.get("name"):
            # æœ€çµ‚æ›´æ–°æ—¥ã‚’å–å¾—
            print(f"  Fetching metadata...")
            updated_at = get_last_commit_date(repo["full_name"], skill_name)

            skill = create_skill_data(repo, skill_name, skill_data, updated_at, repo_statistics)
            skills.append(skill)
            print(f"  âœ“ {skill['name']} ({skill['category']}) - Stars: {skill['stars']:,} / Updated: {skill['updatedAt']}")
        else:
            print(f"  âœ— No valid SKILL.md found")

    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_path = os.path.join(os.path.dirname(__file__), "..", "data", "skills.json")
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(skills, f, ensure_ascii=False, indent=2)

    print(f"\nâœ“ Successfully saved {len(skills)} skills to {output_path}")
    print(f"\nCategories:")
    categories = {}
    for skill in skills:
        categories[skill["category"]] = categories.get(skill["category"], 0) + 1
    for cat, count in sorted(categories.items()):
        print(f"  {cat}: {count}")


if __name__ == "__main__":
    main()
